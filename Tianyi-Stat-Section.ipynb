{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistics\n",
    "\n",
    "Objectives of this notebook : \n",
    "\n",
    "- Find correlation between several variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import scipy.stats as st\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# usual functions (you can put them in a module and import it)\n",
    "\n",
    "# mean\n",
    "def mean(s):\n",
    "    return np.mean(s)\n",
    "\n",
    "# standard deviation\n",
    "def std(s):\n",
    "    return np.std(s)\n",
    "\n",
    "# variance\n",
    "def var(s):\n",
    "    return np.var(s)\n",
    "\n",
    "# covariance\n",
    "def cov(x,y):\n",
    "    return np.cov(x,y, bias = True)[0,1]\n",
    "\n",
    "# correlation\n",
    "def corr(x,y):\n",
    "    return np.corrcoef(x,y)[0,1]\n",
    "\n",
    "# skewness\n",
    "def skew(s):\n",
    "    return st.skew(s)\n",
    "\n",
    "# kurtosis\n",
    "def kurt(s):\n",
    "    return st.kurtosis(s)\n",
    "\n",
    "def stats(s):\n",
    "    print(f'nobs = {len(s)}, minmax = {min(s), max(s)}, mean = {mean(s)}, std = {std(s)}, skewness = {skew(s)}, kurtosis = {kurt(s)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"nba_player_stats_C_Rami.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1 : Bivariate Descriptive Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, I am providing you the tools to analyse the relations between two variables. There are 3 cases.\n",
    "\n",
    "- 2 Numerical Variable\n",
    "- 1 Numerical & 1 Categorical\n",
    "- 2 Categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Two Numerical Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Scatter Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = input(\"Field for x axis\")\n",
    "b = input(\"Field for y axis\")\n",
    "x,y = df[a].fillna(0), df[b].fillna(0)\n",
    "plt.scatter(x,y)\n",
    "plt.xlabel(a)\n",
    "plt.ylabel(b)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. The covariance : It measures joint variability between two random variables.\n",
    "\n",
    "Interpretation : \n",
    "- A high positive value suggests an association exists between the variables, indicating that they tend to vary together.\n",
    "- A negative value indicates that the variables tend to move in opposite directions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.cov(x,y) #If Nan Appears, you fight need to filter records having Nan."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. The Linear Correlation Coefficient is a statistical measure that quantifies the strength and direction of a linear relationship between two variables. \n",
    "\n",
    "Interpretation : \n",
    "- 1 indicates a strong positive linear relationship,\n",
    "- -1 indicates a strong negative linear relationship,\n",
    "- 0 indicates no linear relationship"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.corrcoef(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion : If you end up with something far from 0 at this point, you might want to make a regression because the variance of one variable is linked to the other one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### One Categorical And One Numerical variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Boxplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = input(\"Field for Categorical\")\n",
    "b = input(\"Field for Numerical\")\n",
    "\n",
    "sns.boxplot(data = df, x = a, y = a, orient = 'v')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we want to know what causes the Variance. Is it inter-class or Intra-class. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = len(df[b])\n",
    "np.var(df[b]), df[b].var()*(N-1)/N, df[b].var(ddof = 0)\n",
    "\n",
    "mi = df.groupby(a).mean() \n",
    "si2 = df.groupby('cartel').var(ddof = 0) \n",
    "\n",
    "df[b].value_counts()\n",
    "ni = df.groupby(b).count() \n",
    "\n",
    "intra = np.sum(ni * si2, axis = 0)/N\n",
    "miu = sum(df[b])/len(df[b])\n",
    "inter = np.sum(ni*(mi-miu)**2, axis = 0)/N\n",
    "\n",
    "i= inter/(inter + intra)\n",
    "\n",
    "i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we computed the Empirical Correlation Ratio. What that means is that it is a number between 0 and 1.\n",
    "\n",
    "Interpretation : \n",
    "\n",
    "- When it is 0, the variance is only caused by inter-class variance\n",
    "- When it is 1, the variance is only caused by intra-class variance. The closest to this value, the more there is correlation between the variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Two Categorical Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will skip the plotting because I struggle with this. If someone is kind enough to do it, i'd be happy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will need to create a contingency table in order to use your data. You will then perform a Chi-square independence test and hope that you reject H0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2 : Regression\n",
    "\n",
    "Now, we have seen that there is a link between some variables. When scattered, you sometime now that there is a pattern. We now want to know if it's true and get several information : \n",
    "\n",
    "- What is this pattern as a function? (regression in itself)\n",
    "- Can we predict? (Prediction of values and Confidence interval for the predictions)\n",
    "\n",
    "We are given tools to analyze to type of linear models : \n",
    "\n",
    "1. $ a + bx + cx^2 $ Multiple Linear Regression\n",
    "2. $ a + bx $ Simple linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we can linearize some models throught tough calculations that we have seen in High-School."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Least Square Regression Line"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will first need to find if we can perform a good regression by determining the least square regression line. (finding values of a and b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = input(\"Field for x\")\n",
    "b = input(\"Field for y\")\n",
    "\n",
    "x = df[a]\n",
    "y = df[b]\n",
    "sns.scatterplot(x = x, y = y)\n",
    "plt.show()\n",
    "\n",
    "n = len(x)\n",
    "mx = mean(x)\n",
    "sx = std(x)\n",
    "my = mean(y)\n",
    "sy = std(y)\n",
    "r = corr(x,y) # correlation coefficient\n",
    "n, mx, sx, my, sy, r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = st.linregress(x, y)\n",
    "print(lr,type(lr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the r-value-squared is close to 1, the proportion of the variance explained by the variance is important meaning that prediction is going to be precise. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit = np.polyfit(x,y, 1) # linear fitting\n",
    "print(fit) # slope and value at the origin (b and a in this order)\n",
    "poly = np.poly1d(fit) # create the line poly parametrized by fit\n",
    "sns.scatterplot(x = x, y = y)\n",
    "z = [min(x)*0.95,max(x)*1.05]\n",
    "plt.plot(z,poly(z),'r-', linewidth = 1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prediction"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
